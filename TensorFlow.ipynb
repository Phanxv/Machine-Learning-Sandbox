{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Tensorflow installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from 'c:\\\\Users\\\\phank\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensor\n",
    "A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Scalar (RANK 0 tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_string = tf.Variable(\"This is a tensor string\", tf.string)\n",
    "tensor_int = tf.Variable(420, tf.int16)\n",
    "tensor_float = tf.Variable(69.420, tf.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Vectors/Matrices (RANK >0 tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank1_tensor = tf.Variable([69,420], tf.int16)\n",
    "rank2_tensor = tf.Variable([[49,420],[9,11]], tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.rank(rank2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank2_tensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = tf.ones([2,2,3])\n",
    "print(tensor1)\n",
    "tensor2 = tf.reshape(tensor1,[2,3,2])\n",
    "print(tensor2)\n",
    "tensor3 = tf.reshape(tensor1,[12])\n",
    "print(tensor3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Core Learning Algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear regression is one of the most basic forms of machine learning and is used to predict numeric values.\n",
    "\n",
    "Use when the datapoint is correlated linearly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Data for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 2.5, 3, 4]\n",
    "y = [1, 4, 7, 9, 15]\n",
    "plt.plot(x, y, 'ro')\n",
    "plt.axis([0, 6, 0, 20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line of best fit for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'ro')\n",
    "plt.axis([0, 6, 0, 20])\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model to predicting the Line of best fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset\n",
    "\n",
    "- Titanic dataset contain list and attribute of people boarding Titanic at the time of the crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.pop('n_siblings_spouses')\n",
    "dftrain.pop('fare')\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.sex.value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical and numeric data into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS  = ['sex','parch','class','deck','embark_town','alone']\n",
    "NUMERICAL_COLUMNS = ['age']\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERICAL_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "feature_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process\n",
    "Load small amount of data (batches) into the model using input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=16, shuffle=True, batch_size=32):\n",
    "  def input_function():  # inner function, this will be returned\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est.train(train_input_fn)  # train\n",
    "#result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n",
    "#clear_output()  # clears consoke output\n",
    "#print(result)  # the result variable is simply a dict of stats about our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(linear_est.predict(eval_input_fn))\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for i in range(len(result)) :\n",
    "    print(y_eval.loc[i])\n",
    "    print(result[i][\"probabilities\"][1])\n",
    "    if y_eval.loc[i] == round(result[i][\"probabilities\"][1]) :\n",
    "        correct += 1\n",
    "    else :\n",
    "        incorrect += 1\n",
    "\n",
    "accuracy = (correct / (correct + incorrect)) * 100\n",
    "print(\"CORRECT PREDICTION : \" + str(correct) + '/' + str(correct+incorrect))\n",
    "print(\"INCORRECT PREDICTION : \" + str(incorrect) + '/' + str(correct+incorrect))\n",
    "print(\"ACCURACY : \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset is Iris which is the daataset containing a different species of flower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()\n",
    "train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model\n",
    "- DNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\phank\\\\AppData\\\\Local\\\\Temp\\\\tmp4_xl7co4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[50, 30],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From c:\\Users\\phank\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:90: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.2308007, step = 0\n",
      "INFO:tensorflow:global_step/sec: 175.605\n",
      "INFO:tensorflow:loss = 0.94507265, step = 100 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.853\n",
      "INFO:tensorflow:loss = 0.84087837, step = 200 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.035\n",
      "INFO:tensorflow:loss = 0.78121346, step = 300 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.721\n",
      "INFO:tensorflow:loss = 0.7251201, step = 400 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.715\n",
      "INFO:tensorflow:loss = 0.68134683, step = 500 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.171\n",
      "INFO:tensorflow:loss = 0.6416751, step = 600 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.993\n",
      "INFO:tensorflow:loss = 0.613473, step = 700 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.139\n",
      "INFO:tensorflow:loss = 0.59600174, step = 800 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.853\n",
      "INFO:tensorflow:loss = 0.56291366, step = 900 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.565\n",
      "INFO:tensorflow:loss = 0.5397974, step = 1000 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.292\n",
      "INFO:tensorflow:loss = 0.53142667, step = 1100 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.292\n",
      "INFO:tensorflow:loss = 0.49942297, step = 1200 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.422\n",
      "INFO:tensorflow:loss = 0.49299848, step = 1300 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.565\n",
      "INFO:tensorflow:loss = 0.46203154, step = 1400 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.171\n",
      "INFO:tensorflow:loss = 0.45695636, step = 1500 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.369\n",
      "INFO:tensorflow:loss = 0.4514026, step = 1600 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.131\n",
      "INFO:tensorflow:loss = 0.4236367, step = 1700 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.872\n",
      "INFO:tensorflow:loss = 0.41224626, step = 1800 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.775\n",
      "INFO:tensorflow:loss = 0.40720433, step = 1900 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.993\n",
      "INFO:tensorflow:loss = 0.39820293, step = 2000 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.715\n",
      "INFO:tensorflow:loss = 0.3875271, step = 2100 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.806\n",
      "INFO:tensorflow:loss = 0.36896282, step = 2200 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.242\n",
      "INFO:tensorflow:loss = 0.36179173, step = 2300 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.951\n",
      "INFO:tensorflow:loss = 0.36007926, step = 2400 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.853\n",
      "INFO:tensorflow:loss = 0.35064185, step = 2500 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.292\n",
      "INFO:tensorflow:loss = 0.33985934, step = 2600 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.715\n",
      "INFO:tensorflow:loss = 0.33992288, step = 2700 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.286\n",
      "INFO:tensorflow:loss = 0.3399694, step = 2800 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.762\n",
      "INFO:tensorflow:loss = 0.3270321, step = 2900 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.351\n",
      "INFO:tensorflow:loss = 0.32573652, step = 3000 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.976\n",
      "INFO:tensorflow:loss = 0.29428983, step = 3100 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.413\n",
      "INFO:tensorflow:loss = 0.30292195, step = 3200 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.161\n",
      "INFO:tensorflow:loss = 0.29995784, step = 3300 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.076\n",
      "INFO:tensorflow:loss = 0.29858705, step = 3400 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.043\n",
      "INFO:tensorflow:loss = 0.28994882, step = 3500 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.139\n",
      "INFO:tensorflow:loss = 0.29123643, step = 3600 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.791\n",
      "INFO:tensorflow:loss = 0.27251244, step = 3700 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.817\n",
      "INFO:tensorflow:loss = 0.27547115, step = 3800 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.291\n",
      "INFO:tensorflow:loss = 0.27290887, step = 3900 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.872\n",
      "INFO:tensorflow:loss = 0.2717247, step = 4000 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.351\n",
      "INFO:tensorflow:loss = 0.25294775, step = 4100 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.192\n",
      "INFO:tensorflow:loss = 0.25529528, step = 4200 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.36\n",
      "INFO:tensorflow:loss = 0.25806457, step = 4300 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.215\n",
      "INFO:tensorflow:loss = 0.25508213, step = 4400 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.16\n",
      "INFO:tensorflow:loss = 0.24613906, step = 4500 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.259\n",
      "INFO:tensorflow:loss = 0.24995646, step = 4600 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.871\n",
      "INFO:tensorflow:loss = 0.2431038, step = 4700 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.689\n",
      "INFO:tensorflow:loss = 0.23607603, step = 4800 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.005\n",
      "INFO:tensorflow:loss = 0.24050543, step = 4900 (0.464 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.22278208.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x212a77f37c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating modeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-03-18T14:07:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.84942s\n",
      "INFO:tensorflow:Finished evaluation at 2023-03-18-14:07:18\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.2567342, global_step = 5000, loss = 0.2567342\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user input\n",
      "user input object : {'SepalLength': [5.0], 'SepalWidth': [2.3], 'PetalLength': [3.3], 'PetalWidth': [1.0]}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\phank\\AppData\\Local\\Temp\\tmp4_xl7co4\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Versicolor\" (75.4%)\n"
     ]
    }
   ],
   "source": [
    "input_feature_columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "def usr_input_fn(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "print(\"user input\")\n",
    "for feature in input_feature_columns :\n",
    "    val = input(feature + ' >> ')\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "print('user input object : ' + str(predict))\n",
    "predictions = classifier.predict(input_fn=lambda: usr_input_fn(predict))\n",
    "\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    prob = pred_dict['probabilities'][class_id]\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100*prob))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model\n",
    "\n",
    "finite set of state associated with a probability distribution useful for predicting future event based on past event"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States : Could be anything\n",
    "\n",
    "Observation : Each state will have a particular outcome or observation associated with it\n",
    "\n",
    "Transitions : Each state will have a probability to transition to a different state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Data : Weather model\n",
    "1. Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
    "2. The first day in our sequence has an 80% chance of being cold.\n",
    "3. A cold day has a 30% chance of being followed by a hot day.\n",
    "4. A hot day has a 20% chance of being followed by a cold day.\n",
    "5. On each day the temperature is\n",
    " normally distributed with mean and standard deviation 0 and 5 on\n",
    " a cold day and mean and standard deviation 15 and 10 on a hot day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "initial_distribution = tfd.Categorical(probs=[0.2, 0.8]) \n",
    "transition_distribution = tfd.Categorical(probs=[[0.5, 0.5],\n",
    "                                                 [0.2, 0.8]])\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
